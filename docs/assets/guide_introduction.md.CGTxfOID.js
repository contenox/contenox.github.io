import{_ as a,o as t,c as s,ag as e}from"./chunks/framework.DQQHyi2x.js";const u=JSON.parse('{"title":"Introduction","description":"","frontmatter":{},"headers":[],"relativePath":"guide/introduction.md","filePath":"guide/introduction.md"}'),o={name:"guide/introduction.md"};function i(r,n,l,d,p,c){return t(),s("div",null,[...n[0]||(n[0]=[e(`<h1 id="introduction" tabindex="-1">Introduction <a class="header-anchor" href="#introduction" aria-label="Permalink to &quot;Introduction&quot;">​</a></h1><p>Contenox is a self-hostable runtime for building <strong>observable, deterministic AI workflows</strong> as explicit state machines.</p><p>Instead of wiring prompts together with ad-hoc Python glue, you define your AI behaviour as a <strong>task chain</strong> — a JSON graph of typed tasks, transitions, and tool calls. Every step is inspectable, replayable, and testable.</p><h2 id="three-editions" tabindex="-1">Three editions <a class="header-anchor" href="#three-editions" aria-label="Permalink to &quot;Three editions&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Edition</th><th>Use case</th><th>Entry point</th></tr></thead><tbody><tr><td><strong>vibe</strong> CLI</td><td>Local AI agent on your machine</td><td><code>vibe run</code></td></tr><tr><td><strong>Runtime API</strong></td><td>Self-hosted REST backend for apps</td><td>Docker / <code>go run</code></td></tr><tr><td><strong>Enterprise (EE)</strong></td><td>Multi-tenant, dashboard, RBAC</td><td><code>enterprise/</code></td></tr></tbody></table><p><strong>vibe is the flagship.</strong> This documentation focuses on it first. The runtime API and EE share the same chain / hook / task engine underneath.</p><h2 id="how-it-works" tabindex="-1">How it works <a class="header-anchor" href="#how-it-works" aria-label="Permalink to &quot;How it works&quot;">​</a></h2><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>User input</span></span>
<span class="line"><span>    │</span></span>
<span class="line"><span>    ▼</span></span>
<span class="line"><span>┌─────────────────────┐</span></span>
<span class="line"><span>│   Task Chain (JSON) │  ← you define this</span></span>
<span class="line"><span>│  task → task → …   │</span></span>
<span class="line"><span>└─────────────────────┘</span></span>
<span class="line"><span>    │</span></span>
<span class="line"><span>    ▼</span></span>
<span class="line"><span>Model (Ollama / OpenAI / vLLM / Gemini)</span></span>
<span class="line"><span>    │</span></span>
<span class="line"><span>    ├─ tool call? → Hook (local shell, remote API)</span></span>
<span class="line"><span>    │                    │</span></span>
<span class="line"><span>    └─ text reply ←──────┘</span></span></code></pre></div><p>Each task has a <strong>handler</strong> (what it does), an optional <strong>LLM config</strong> (which model, which hooks), and a <strong>transition</strong> (where to go next). The chain engine drives the loop — the model doesn&#39;t.</p><h2 id="next-steps" tabindex="-1">Next steps <a class="header-anchor" href="#next-steps" aria-label="Permalink to &quot;Next steps&quot;">​</a></h2><ul><li><a href="/docs/guide/quickstart.html">Quickstart</a> — install vibe and run your first chain in 5 minutes</li><li><a href="/docs/guide/concepts.html">Core Concepts</a> — chains, tasks, hooks, transitions explained</li><li><a href="/docs/chains/">Chains reference</a> — build your own chains from scratch</li></ul>`,11)])])}const g=a(o,[["render",i]]);export{u as __pageData,g as default};
